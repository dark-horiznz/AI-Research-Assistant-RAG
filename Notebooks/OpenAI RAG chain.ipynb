{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ac2008-873b-4094-9b8f-638957e739da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain_community tiktoken langchain-openai langchainhub langchain pinecone pypdf langchain_pinecone --upgrade pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9056e14c-b5cc-4403-be69-728f7f31ee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import unstructured\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = '<YOUR API KEY>'\n",
    "os.environ['OPENAI_API_KEY'] = '<YOUR API KEY>'\n",
    "os.environ['PINECONE_API_KEY'] = '<YOUR API KEY>'\n",
    "os.environ['PINECONE_ENV'] = 'rag'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f7171879-356c-44c8-b51d-44b65d4455fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from pinecone import Pinecone\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pdfplumber\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "38bf653f-8cb9-4d7d-aa57-4f7d0c9b3c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_from_doc(pdf_path):\n",
    "    docs = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            text = page.extract_text() or \"\"\n",
    "            tables = page.extract_tables()\n",
    "            table_text = \"\\n\".join([\n",
    "                \"\\n\".join([\"\\t\".join(cell if cell is not None else \"\" for cell in row) for row in table])\n",
    "                for table in tables if table\n",
    "            ]) if tables else \"\"\n",
    "            images = page.images\n",
    "            image_text = f\"[{len(images)} image(s) detected]\" if images else \"\"\n",
    "            content = f\"{text}\\n\\n{table_text}\\n\\n{image_text}\".strip()\n",
    "            if content:\n",
    "                docs.append(Document(page_content=content, metadata={\"page\": i + 1}))\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9a28389f-042a-481b-ac2b-1cb82d6a84b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data_from_doc('/Users/aditya/Desktop/RAG/Corpus.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3dc36ff2-06d4-44be-935a-14eb46f04140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_chunks(docs, chunk_len=1000, chunk_overlap=200):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_len, chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(docs)\n",
    "    return [Document(page_content=chunk.page_content, metadata=chunk.metadata) for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e7a7bb5c-9ba7-4878-8070-ae203bdec194",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = make_chunks(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9f65e973-e791-4bd7-8706-7705cfbd9e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(api_key=os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c7143093-5b5e-49f8-a8d9-87ab31a66079",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(os.environ['PINECONE_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5b105891-c3f6-4710-93ac-8c192834ea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field = \"text\"\n",
    "vectorstore = PineconeVectorStore.from_documents(\n",
    "    splits,\n",
    "    embeddings,\n",
    "    index_name = os.environ['PINECONE_ENV']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7c729d52-b7a8-4759-bc41-960e8544276d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "65c459b8-2a9d-47b6-8ba8-2a7a0722b0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are an AI assistant answering questions based on retrieved documents and additional context. \n",
    "Use the provided context from both database retrieval and additional sources to answer the question. \n",
    "\n",
    "- **Discard irrelevant context:** If one of the contexts (retrieved or additional) does not match the question, ignore it.\n",
    "- **Highlight conflicting information:** If multiple sources provide conflicting information, explicitly mention it by saying:\n",
    "  - \"According to the retrieved context, ... but as per internet sources, ...\"\n",
    "  - \"According to the retrieved context, ... but as per internet sources, ...\"\n",
    "- **Prioritize accuracy:** If neither context provides a relevant answer, say \"I don't know\" instead of guessing.\n",
    "\n",
    "Provide concise yet informative answers, ensuring clarity and completeness.\n",
    "\n",
    "Retrieved Context: {context}\n",
    "Additional Context: {additional_context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\\n\\nRetrieved Context: {context}\\n\\nAdditional Context: {additional_context}\"),\n",
    "    ]\n",
    ")\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "chain = create_retrieval_chain(retriever , question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "41530a9e-3ec7-4119-804f-194f45792ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_llm(question, additional_context=\"\"):\n",
    "    input_data = {\n",
    "        \"input\": question,\n",
    "        \"additional_context\": additional_context  \n",
    "    }\n",
    "    out = chain.invoke(input_data)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "24f91e50-5975-48d9-9644-abe5cc633782",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = chat_with_llm('What does this company sell?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "178d291f-abbd-421f-bae7-80c066072d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This company sells wine, specifically Napa Valley Cabernet Sauvignon aged for 12 years in French oak. The wine offers pronounced aromas and a decadent palate. They also utilize the Solera method in the production of fortified wines like Sherry and Madeira.'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93469bed-5c2b-4a2f-930e-b4c56424447f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
