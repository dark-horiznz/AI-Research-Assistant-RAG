{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23626206-1aab-4053-8a7d-125df12ca6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain langchain_groq langchain_pinecone pinecone-client pypdf langchain groq google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72ef3cf5-5291-4214-8ef2-fdaa670e86ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "import google.generativeai as genai\n",
    "from langchain.document_loaders import UnstructuredPDFLoader, PyPDFLoader\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pinecone import Pinecone\n",
    "import pdfplumber\n",
    "from langchain.schema import Document\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from typing import List\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98f084ce-cfc2-472a-9df5-b727b94a1bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import unstructured\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = '<YOUR API KEY>'\n",
    "os.environ['GROQ_API_KEY'] = '<YOUR API KEY>'\n",
    "os.environ['PINECONE_API_KEY'] = '<YOUR API KEY>'\n",
    "os.environ['PINECONE_ENV'] = 'gemini-rag'\n",
    "os.environ[\"GEMINI_API_KEY\"] = '<YOUR API KEY>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9ba8432-86af-4964-9a4c-a377529173ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_from_doc(pdf_path):\n",
    "    docs = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            text = page.extract_text() or \"\"\n",
    "            tables = page.extract_tables()\n",
    "            table_text = \"\\n\".join([\n",
    "                \"\\n\".join([\"\\t\".join(cell if cell is not None else \"\" for cell in row) for row in table])\n",
    "                for table in tables if table\n",
    "            ]) if tables else \"\"\n",
    "            images = page.images\n",
    "            image_text = f\"[{len(images)} image(s) detected]\" if images else \"\"\n",
    "            content = f\"{text}\\n\\n{table_text}\\n\\n{image_text}\".strip()\n",
    "            if content:\n",
    "                docs.append(Document(page_content=content, metadata={\"page\": i + 1}))\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79f06a95-fcac-4abb-b927-0b4354faa53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data_from_doc('/Users/aditya/Desktop/Aditya_s_Resume-4.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43abdc9e-2bcc-47c5-871a-735ea5c96f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_chunks(docs, chunk_len=1000, chunk_overlap=200):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_len, chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(docs)\n",
    "    return [Document(page_content=chunk.page_content, metadata=chunk.metadata) for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efc2f7a7-f0a8-46d2-bf3f-6e26c1e7cdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = make_chunks(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e35feb43-2eb0-49c2-8df6-9b1ec47bc299",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5fa1ce1-d86f-428d-934f-3aaef147ccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import numpy as np\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from typing import List\n",
    "\n",
    "class GeminiEmbeddings(Embeddings):\n",
    "    def __init__(self, api_key):\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model_name = \"models/embedding-001\"  \n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        return [self._convert_to_float32(genai.embed_content(model=self.model_name, content=text, task_type=\"retrieval_document\")[\"embedding\"]) for text in texts]\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        response = genai.embed_content(model=self.model_name, content=text, task_type=\"retrieval_query\")\n",
    "        return self._convert_to_float32(response[\"embedding\"])\n",
    "\n",
    "    @staticmethod\n",
    "    def _convert_to_float32(embedding):\n",
    "        return np.array(embedding, dtype=np.float32).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "997f03d4-0d83-41cb-9b09-68e5570239cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = GeminiEmbeddings(api_key=os.environ[\"GEMINI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9fcbf57-404f-49d1-bcc0-00c82c304339",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(os.environ['PINECONE_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76d3c29b-9ee7-4404-b3d4-61c1b9f5deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field = \"text\"\n",
    "vectorstore = PineconeVectorStore.from_documents(\n",
    "    splits,\n",
    "    embeddings,\n",
    "    index_name = os.environ['PINECONE_ENV']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "495e22cf-a43e-4fd1-ba6b-1ee55310794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"gemma2-9b-it\",\n",
    "    \"llama-3.3-70b-versatile\",\n",
    "    \"llama-3.1-8b-instant\",\n",
    "    \"llama-guard-3-8b\",\n",
    "    \"llama3-70b-8192\",\n",
    "    \"llama3-8b-8192\",\n",
    "    \"mixtral-8x7b-32768\",\n",
    "    \"deepseek-r1-distill-llama-70b\",\n",
    "    \"llama-3.3-70b-specdec\",\n",
    "    \"llama-3.2-1b-preview\",\n",
    "    \"llama-3.2-3b-preview\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be2204af-3bc4-45a5-9dd9-4c75c94969aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model_name=models[5], temperature=0.75, api_key=os.environ['GROQ_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df1d350b-5d2f-4220-a5ab-202a95d43224",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an AI assistant answering questions based on retrieved documents and additional context. \n",
    "Use the provided context from both database retrieval and additional sources to answer the question. \n",
    "\n",
    "- **Discard irrelevant context:** If one of the contexts (retrieved or additional) does not match the question, ignore it.\n",
    "- **Highlight conflicting information:** If multiple sources provide conflicting information, explicitly mention it by saying:\n",
    "  - \"According to the retrieved context, ... but as per internet sources, ...\"\n",
    "  - \"According to the retrieved context, ... but as per internet sources, ...\"\n",
    "- **Prioritize accuracy:** If neither context provides a relevant answer, say \"I don't know\" instead of guessing.\n",
    "\n",
    "Provide concise yet informative answers, ensuring clarity and completeness.\n",
    "\n",
    "Retrieved Context: {context}\n",
    "Additional Context: {additional_context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\\n\\nRetrieved Context: {context}\\n\\nAdditional Context: {additional_context}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33b9f47f-faf8-4256-b7ba-def64b2050b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dac7b8a-ccdc-42cf-a3f7-f442c102a3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "644f84ac-bd06-4434-a5ba-1b8ee211525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a6a4834-ba18-4a33-89d5-523f9d3aa37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_llm(question, additional_context=\"\"):\n",
    "    input_data = {\n",
    "        \"input\": question,\n",
    "        \"additional_context\": additional_context  \n",
    "    }\n",
    "    out = chain.invoke(input_data)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27ed860f-9a29-493c-80fa-179937b36dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = chat_with_llm('Tell me which collage did Aditya Attend?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ddaff2b3-232e-47ca-9aa0-91805969bbc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the retrieved context, Aditya Singh attended Rajiv Gandhi Institute of Petroleum Technology (RGIPT) for his B.Tech. in Computer Science and Engineering, starting from October 2022.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c610ce87-ec14-4481-86c9-3b20422a7848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
